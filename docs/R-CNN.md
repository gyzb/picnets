论文链接：[Rich feature hierarchies for accurate object detection and semantic segmentation](https://arxiv.org/pdf/1311.2524.pdf)

#论文内容笔记：

1、之所以把R-CNN放在第一个，是因为R-CNN对于目标检测是个里程碑的算法，借助CNN良好的特征提取和分类性能，通过RegionProposal方法实现目标检测问题的转化。

2、在此之前，目标检测的方法是大部分依赖SIFT和HOG。

3、R-CNN首次显示，与基于类似HOG的简单功能的系统相比，CNN可以在PASCAL VOC上显着提高目标检测性能。


4、网络具有五个卷积层，具有非常大的接收场（195×195像素）并在输入图像中大步前进（32×32像素）。


5、本文的第二个主要贡献是表明，在大型辅助数据集（ILSVRC）上进行有监督的预训练，然后在小型数据集（PASCAL）上进行领域特定的微调，是在数据量较大时学习大容量CNN的有效范例。


6、我们的物体检测系统由三个模块组成：第一个模块生成与类别无关的区域提议，这些提议定义了可用于探测器的候选检测集。 第二个模块是一个大型卷积神经网络，它从每个区域提取一个固定长度的特征向量。 第三个模块是一组特定于类别的线性SVM。


7、区域提案：方法。示例包括：对象性，选择性搜索，与类别无关的对象提议，约束参数最小割（CPMC），多尺度组合分组和Cires¸an等。  
特征提取：使用Caffe实现，从每个区域建议中提取4096维特征向量。通过将均值减去后的227×227RGB图像通过五个卷积层和两个完全连接的层进行正向传播来计算特征。必须首先将该区域中的图像数据转换为与CNN兼容的形式（其架构要求输入固定227×227像素大小）

8、测试时间阶段的检测：提取大约2000个区域建议；对每个建议进行变形；通过CNN进行传播；计算特征，对于每个类别使用针对该类别训练的SVM为每个提取的特征向量评分；应用贪婪的非最大抑制计算记分区域（如果该区域的交点重叠（IoU）重叠且得分较高的选定区域大于学习阈值，则拒绝该区域）。

9、除了将CNN的ImageNet特定于1000路分类层替换为随机初始化的（N + 1）路分类层（其中N是对象类的数量，再加上1作为背景）之外，CNN的体系结构保持不变。对于VOC，N = 20；对于ILSVRC2013，N = 200。  
以0.001（初始预训练速率的1/10）的学习速率开始SGD。  
对32个正窗口（在所有类中）和96个背景窗口进行统一采样，以构建大小为128的微型批处理。

10、PASCAL VOC 2010-12上的结果是在mAP方面实现了很大的提高，从35.1％提高到了53.7％，而且还快得多  
ILSVRC2013 detection的结果是R-CNN的mAP为31.4％，大大超过了OverFeat的第二佳结果24.3％。

11、挑选出网络中的一个特定单元（功能），并像使用它本身就是对象检测器一样使用它。

12、可视化来自pool，pool是网络第五个也是最后一个卷积层的最大池输出。 pool功能图为6×6×256 = 9216维。忽略边界效应，每个pool单元在原始227×227像素输入中具有195×195像素的接收场。中央pool的视野几乎是全局的，而靠近边缘的泳池则具有较小的固定支撑。  

13、最后两层总结如下：fc层已完全连接到pool。为了计算特征，它会将4096×9216权重矩阵乘以pool特征图（重塑为9216维向量），然后添加一个偏差向量。该中间矢量是逐分量半波整流的（x←max（0，x））。
fc层是网络的最后一层。它是通过将fc计算的特征乘以4096×4096权重矩阵并类似地添加一个偏置矢量并应用半波整流来实现的。

14、带有O-Net的RCNN明显优于带有TNet的R-CNN，将mAP从58.5％提高到66.0％。但是，在计算时间方面存在相当大的缺陷，O-Net的前向传递比T-Net花费大约7倍的时间。

15、从val集中随机采样每个图像，并显示所有检测器的所有检测结果，其精度均大于0.5。

16、ILSVRC2013检测数据集分为三组：训练（395,918），val（20,121）和测试（40,152），其中每组中的图像数都用括号括起来。

17、总体策略是严重依赖val集，并使用一些火车图像作为积极实例的辅助来源。 val上，选择性搜索平均每幅图像产生2403个区域提议，所有地面真相边界框的召回率达到91.6％（阈值为0.5 IoU）。召回率明显低于PASCAL，后者约为98％，表明在区域提案阶段仍有很大的改进空间。

18、R-CNN中的三个过程需要训练数据：（1）CNN微调，（2）检测器SVM训练和，（3）边界框回归器训练。



代码地址：[https://github.com/rbgirshick/rcnn](https://github.com/rbgirshick/rcnn)（注意代码已经不再维护）


